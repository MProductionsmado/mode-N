# Minecraft 3D Nature Asset Generator - Schnellstart üöÄ

## Neuer RunPod Setup (START HIER!) 

### Option A: Automatisches Setup (EMPFOHLEN)

```bash
# 1. Repository klonen
git clone https://github.com/MProductionsmado/mode-N.git "model N"
cd "model N"

# 2. Setup-Script ausf√ºhren (macht alles automatisch)
bash scripts/setup_runpod.sh
```

### Option B: Manuelles Setup

```bash
# 1. Repository klonen
git clone https://github.com/MProductionsmado/mode-N.git "model N"
cd "model N"

# 2. Virtual Environment
python3 -m venv venv
source venv/bin/activate

# 3. Dependencies
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install pytorch-lightning sentence-transformers pyyaml nbtlib numpy

# 4. WICHTIG: Sentence-Transformers Modell herunterladen
python3 scripts/download_model.py

# 5. Models-Verzeichnis erstellen
mkdir -p models
```

---

## Installation (Local Windows)

### 1. Python-Umgebung erstellen

```powershell
# Python 3.9+ erforderlich
python -m venv venv
.\venv\Scripts\Activate.ps1
```

### 2. Dependencies installieren

```powershell
pip install --upgrade pip
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install pytorch-lightning sentence-transformers pyyaml nbtlib numpy
```

## Workflow

### Schritt 1: Daten Preprocessing

Analysiere zun√§chst den Datensatz:

```powershell
python scripts/preprocess_data.py --analyze-only
```

Dann verarbeite alle Schematics:

```powershell
python scripts/preprocess_data.py --input out --output data
```

**Output**:
- `data/processed/` - Voxel Arrays als .npy Dateien
- `data/splits/` - Train/Val/Test Metadata
- `data/dataset_statistics.json` - Datensatz-Statistiken

‚è±Ô∏è **Dauer**: ~10-30 Minuten f√ºr 9180 Dateien

### Schritt 2: Training

```powershell
python scripts/train.py --config config/config.yaml
```

**Optional**: Debug-Modus f√ºr schnellen Test:
```powershell
python scripts/train.py --debug
```

**Optional**: Training fortsetzen:
```powershell
python scripts/train.py --resume models/last.ckpt
```

**Training √ºberwachen**:
```powershell
tensorboard --logdir logs
```

‚è±Ô∏è **Dauer**: 
- GPU (RTX 3080): ~2-4 Stunden f√ºr 200 Epochs
- CPU: ~24-48 Stunden

### Schritt 3: Asset Generierung

Einzelnes Asset generieren:

```powershell
python scripts/generate.py --checkpoint models/best.ckpt --prompt "big oak tree" --output generated.schem
```

Mehrere Variationen:

```powershell
python scripts/generate.py --checkpoint models/best.ckpt --prompt "birch tree with fall leaves" --num-samples 5 --output generated/tree.schem
```

**Interaktiver Modus**:

```powershell
python scripts/generate.py --interactive
```

### Schritt 4: Evaluation

```powershell
python scripts/evaluate.py --checkpoint models/best.ckpt --visualize --output evaluation
```

## Beispiel-Prompts

### B√§ume
- `"oak tree"`
- `"big birch tree"`
- `"huge oak tree"`
- `"big birch tree with fall leaves"`
- `"spruce tree"`

### B√ºsche
- `"bush"`
- `"big bush"`
- `"small oak bush"`

### Spezielle Strukturen
- `"beehive in oak planks"`
- `"bee nest"`

## Konfiguration anpassen

Editiere `config/config.yaml` f√ºr:

- **Modellgr√∂√üe**: `model.encoder.channels`, `model.sizes.*.latent_dim`
- **Batch Size**: `training.batch_size` (reduziere bei GPU-OOM)
- **Learning Rate**: `training.learning_rate`
- **VAE Beta**: `model.vae.beta` (h√∂her = weniger Diversit√§t, bessere Rekonstruktion)

## Tipps & Tricks

### GPU Memory Issues

Falls "CUDA out of memory":

1. Reduziere Batch Size in `config/config.yaml`:
   ```yaml
   training:
     batch_size: 8  # statt 16
   ```

2. Nutze Mixed Precision:
   ```yaml
   hardware:
     precision: 16  # statt 32
   ```

### CPU Training

√Ñndere in `config/config.yaml`:
```yaml
hardware:
  device: "cpu"
  num_workers: 2
```

### Bessere Diversit√§t

Erh√∂he Temperature beim Generieren:
```powershell
python scripts/generate.py --checkpoint models/best.ckpt --prompt "oak tree" --temperature 1.5
```

### Bessere Qualit√§t

- Trainiere l√§nger (mehr Epochs)
- Erh√∂he KL-Annealing-Dauer
- Reduziere VAE Beta f√ºr bessere Rekonstruktion

## Troubleshooting

### Import Error: nbtlib

```powershell
pip install nbtlib
```

### CUDA not available

Installiere PyTorch mit CUDA-Support:
```powershell
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Datei nicht gefunden

Stelle sicher, dass du im Projektverzeichnis bist:
```powershell
cd "c:\Users\priva\Documents\MProductions\model N"
```

## Projektstruktur

```
model N/
‚îú‚îÄ‚îÄ out/                       # Original .schem Dateien (9180 Assets)
‚îú‚îÄ‚îÄ data/                      # Nach Preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ processed/             # .npy Voxel-Arrays
‚îÇ   ‚îú‚îÄ‚îÄ splits/                # Train/Val/Test Metadata
‚îÇ   ‚îî‚îÄ‚îÄ dataset_statistics.json
‚îú‚îÄ‚îÄ models/                    # Gespeicherte Checkpoints
‚îú‚îÄ‚îÄ logs/                      # TensorBoard Logs
‚îú‚îÄ‚îÄ generated/                 # Generierte Assets
‚îú‚îÄ‚îÄ evaluation/                # Evaluation-Ergebnisse
‚îú‚îÄ‚îÄ src/                       # Source Code
‚îú‚îÄ‚îÄ scripts/                   # Haupt-Scripts
‚îú‚îÄ‚îÄ config/                    # Konfiguration
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## N√§chste Schritte

1. **Experimentiere mit Prompts**: Teste verschiedene Beschreibungen
2. **Fine-Tuning**: Trainiere auf spezifischen Asset-Typen
3. **Integration**: Nutze die generierten Assets in deinem Projekt
4. **Erweitere Vocabulary**: F√ºge mehr Bl√∂cke hinzu in `config/config.yaml`

## Support

- Schau in die Logs: `logs/` und Tensorboard
- Teste mit `--debug` Flag
- Pr√ºfe `data/dataset_statistics.json` f√ºr Datensatz-Insights
